{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following line if you don't have any of the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\ivanl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.11.1)\r\n",
      "Requirement already satisfied: pandas in c:\\users\\ivanl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.25.3)\r\n",
      "Requirement already satisfied: numpy in c:\\users\\ivanl\\appdata\\roaming\\python\\python37\\site-packages (1.18.1)\r\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\ivanl\\appdata\\roaming\\python\\python37\\site-packages (from statsmodels) (1.4.1)\r\n",
      "Requirement already satisfied: patsy>=0.5 in c:\\users\\ivanl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from statsmodels) (0.5.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\ivanl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2.8.1)\r\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\ivanl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas) (2019.3)\r\n",
      "Requirement already satisfied: six in c:\\users\\ivanl\\appdata\\roaming\\python\\python37\\site-packages (from patsy>=0.5->statsmodels) (1.13.0)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\r\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\r\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# pip install statsmodels pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "\n",
    "import data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_prep.get_lagged(\"./data/XLE_energy_etf.csv\", n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"./data/SnP_500.csv\", index_col=\"Date\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_perc_returns = data_prep.get_perc_return(\"./data/SnP_500.csv\", column_name=\"Open\")\n",
    "df_perc_returns.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way returns are distributed shows a stationary process with no correlation with time \n",
    "This also leads us to try out GARCH models since we proabably can model these spikes in volatility.\n",
    "\n",
    "Following which, we'll look at the full dataset, a concatnation of all the variables together with S&P500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/output.csv\", index_col=\"Date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns are laballed as such:  VARIABLE_SECTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP_daily_ret = (df['Adj Close_SNP500']/df['Adj Close_SNP500'].shift(1)) - 1\n",
    "SNP_daily_ret = SNP_daily_ret.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg, ar_select_order\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mod = AutoReg(SNP_daily_ret, 1)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(SNP_daily_ret, lags=30)\n",
    "plt.show()\n",
    "plot_pacf(SNP_daily_ret, lags=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ACF shows that after lags of t=3, autocorrelation stays near 0 which means a **MA(3)** model\n",
    "\n",
    "The PACF shows that after lags of t=3, autocorrelation stays near 0 which means an **AR(3)** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mod = AutoReg(SNP_daily_ret, 3)\n",
    "res = mod.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ar3 = ARMA(SNP_daily_ret, order=[3,0])\n",
    "ar3_fit = ar3.fit(disp=0)\n",
    "print (ar3_fit.summary())\n",
    "print('\\n')\n",
    "\n",
    "ma3 = ARMA(SNP_daily_ret, order=[0,3])\n",
    "ma3_fit = ma3.fit(disp=0)\n",
    "print (ma3_fit.summary())\n",
    "print('\\n')\n",
    "\n",
    "arma11 = ARMA(SNP_daily_ret, order=[1,1])\n",
    "arma11_fit = arma11.fit(disp=0)\n",
    "print (arma11_fit.summary())\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC values for all the models are extremely similar and hence we look to BIC to decide the best model()\n",
    "\n",
    "It seems like ARMA(1,1) has the lowest BIC so we should benchmark ARMA(1,1) for comparison as well. \n",
    "\n",
    "However, as shown later, adding MA(q) to AR(3) to eliminate autocorrelations yields higher AIC than ARMA(1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some usful attributes that might be used in future\n",
    "\"\"\"\n",
    "arma33_fit.aic\n",
    "arma33_fit.bic\n",
    "arma33_fit.fittedvalues  ## return fitted values of the model\n",
    "arma33_fit.predict(start=2568, end=2570)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_acf(ar3_fit.fittedvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 lags are present in AR(3) model so we try to fir ARMA(3,2) to rid of the autocorrelations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arma32 = ARMA(SNP_daily_ret, order=[3,2])\n",
    "arma32_fit = arma32.fit(disp=0)\n",
    "print (arma32_fit.summary())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIC at -16218.540 is lower than all the previous models hence we also benchmarh ARMA(3,2).\n",
    "\n",
    "So far, our benchmarked models are:\n",
    "- AR(3)\n",
    "- ARMA(1,1)\n",
    "- ARMA(3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, we add more variables, to build ADL models that would hopefully beat our benchmark models\n",
    "\n",
    "The easiest way to implement multivariate autoregressions in Python would be Vector Autoregressions(VAR) where each lags would be a vector of size N*K where:\n",
    "- N = No. of observations\n",
    "- K = No. of variables\n",
    "\n",
    "More info is shown [here](https://www.statsmodels.org/devel/vector_ar.html#var)\n",
    "\n",
    "Once again, we obtain **various VAR(q)** models and compare AIC, BIC to select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding more variables\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "def build_and_model_VAR(main_df:pd.DataFrame, var2add:list ):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    main_df - output.csv which has ALL the variables\n",
    "    var2add - the industry, eg. Pharm. The value MUST be inside the colname \n",
    "    \"\"\"\n",
    "    temp_df = pd.DataFrame()\n",
    "    for var in var2add:\n",
    "        for col in main_df.columns:\n",
    "            if \"Open_\"+var in col or \"Volume_\" + var in col:\n",
    "                try:\n",
    "                    temp_df.columns\n",
    "                except:\n",
    "                    temp_df = main_df[col]\n",
    "                else:\n",
    "                    temp_df = pd.concat([temp_df, main_df[col]], axis=1)\n",
    "                    \n",
    "    temp_df['Open_SNP500'] = main_df['Open_SNP500']\n",
    "    temp_df['Volume_SNP500'] = main_df['Volume_SNP500']\n",
    "    \n",
    "    temp_df.index = main_df.index\n",
    "        \n",
    "    return temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pharm_utils = build_and_model_VAR(df, [\"Pharm\",\"Utilities\"])\n",
    "\n",
    "ADL_pharmutils = VAR(endog=pharm_utils['Open_SNP500'], exog=pharm_utils.drop('Open_SNP500',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_utils.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SNP_daily_ret.shape)\n",
    "pharm_utils.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## forecasting\n",
    "lag_order = results.k_ar\n",
    "lag_order\n",
    "# results.forecast(data.values[-lag_order:], 5)\n",
    "# results.plot_forecast(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can do 2 tests as well, Granger casuality and Normality\n",
    "results.test_causality('Open_SNP500', ['Open_Utilities', 'Open_Pharm'], kind='f')\n",
    "# results.test_normality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
