{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Time Series Forecasting Recurrent Neural Network (RNN) </h1>\n",
    "\n",
    "This notebook aims to use deep learning to forecast the time series the \"CLOSE\" of the SNP 500 stock using the stock data from other industries. \n",
    "\n",
    "Libraries of interest: <b>\n",
    "    \n",
    "    TensorFlow\n",
    "    Keras\n",
    "    \n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the following libraries if you do not have them:\n",
    "# !pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.backend import square, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open_Pharm</th>\n",
       "      <th>High_Pharm</th>\n",
       "      <th>Low_Pharm</th>\n",
       "      <th>Close_Pharm</th>\n",
       "      <th>Adj Close_Pharm</th>\n",
       "      <th>Volume_Pharm</th>\n",
       "      <th>Open_Semicon</th>\n",
       "      <th>High_Semicon</th>\n",
       "      <th>Low_Semicon</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Utilities</th>\n",
       "      <th>Close_Utilities</th>\n",
       "      <th>Adj Close_Utilities</th>\n",
       "      <th>Volume_Utilities</th>\n",
       "      <th>Open_Consumer</th>\n",
       "      <th>High_Consumer</th>\n",
       "      <th>Low_Consumer</th>\n",
       "      <th>Close_Consumer</th>\n",
       "      <th>Adj Close_Consumer</th>\n",
       "      <th>Volume_Consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/1/2010</td>\n",
       "      <td>33.150002</td>\n",
       "      <td>33.544998</td>\n",
       "      <td>33.020000</td>\n",
       "      <td>33.535000</td>\n",
       "      <td>26.125103</td>\n",
       "      <td>1622800</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>28.660000</td>\n",
       "      <td>28.299999</td>\n",
       "      <td>...</td>\n",
       "      <td>31.010000</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>21.588554</td>\n",
       "      <td>8217600</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>30.110001</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.967613</td>\n",
       "      <td>5443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/2010</td>\n",
       "      <td>33.580002</td>\n",
       "      <td>33.580002</td>\n",
       "      <td>33.134998</td>\n",
       "      <td>33.220001</td>\n",
       "      <td>25.879725</td>\n",
       "      <td>1933200</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>28.540001</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.559999</td>\n",
       "      <td>30.709999</td>\n",
       "      <td>21.331547</td>\n",
       "      <td>18023700</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>29.820000</td>\n",
       "      <td>30.110001</td>\n",
       "      <td>26.062828</td>\n",
       "      <td>6162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/1/2010</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>33.384998</td>\n",
       "      <td>33.169998</td>\n",
       "      <td>33.384998</td>\n",
       "      <td>26.008247</td>\n",
       "      <td>1492400</td>\n",
       "      <td>28.209999</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.690001</td>\n",
       "      <td>30.889999</td>\n",
       "      <td>21.456575</td>\n",
       "      <td>12745100</td>\n",
       "      <td>30.090000</td>\n",
       "      <td>30.219999</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>30.150000</td>\n",
       "      <td>26.097452</td>\n",
       "      <td>4246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/1/2010</td>\n",
       "      <td>33.285000</td>\n",
       "      <td>33.419998</td>\n",
       "      <td>33.230000</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>25.965412</td>\n",
       "      <td>764600</td>\n",
       "      <td>28.090000</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.639999</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>21.359331</td>\n",
       "      <td>6563100</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>26.313848</td>\n",
       "      <td>5736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8/1/2010</td>\n",
       "      <td>33.259998</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>33.185001</td>\n",
       "      <td>33.340000</td>\n",
       "      <td>25.973190</td>\n",
       "      <td>1218200</td>\n",
       "      <td>27.940001</td>\n",
       "      <td>28.549999</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>...</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>30.719999</td>\n",
       "      <td>21.338493</td>\n",
       "      <td>6267600</td>\n",
       "      <td>30.290001</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>30.120001</td>\n",
       "      <td>30.389999</td>\n",
       "      <td>26.305195</td>\n",
       "      <td>6438000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  Open_Pharm  High_Pharm  Low_Pharm  Close_Pharm  Adj Close_Pharm  \\\n",
       "0  4/1/2010   33.150002   33.544998  33.020000    33.535000        26.125103   \n",
       "1  5/1/2010   33.580002   33.580002  33.134998    33.220001        25.879725   \n",
       "2  6/1/2010   33.250000   33.384998  33.169998    33.384998        26.008247   \n",
       "3  7/1/2010   33.285000   33.419998  33.230000    33.330002        25.965412   \n",
       "4  8/1/2010   33.259998   33.369999  33.185001    33.340000        25.973190   \n",
       "\n",
       "   Volume_Pharm  Open_Semicon  High_Semicon  Low_Semicon  ...  Low_Utilities  \\\n",
       "0       1622800     28.350000     28.660000    28.299999  ...      31.010000   \n",
       "1       1933200     28.450001     28.540001    28.080000  ...      30.559999   \n",
       "2       1492400     28.209999     28.450001    28.080000  ...      30.690001   \n",
       "3        764600     28.090000     28.160000    27.760000  ...      30.639999   \n",
       "4       1218200     27.940001     28.549999    27.870001  ...      30.520000   \n",
       "\n",
       "   Close_Utilities  Adj Close_Utilities  Volume_Utilities  Open_Consumer  \\\n",
       "0        31.080000            21.588554           8217600      29.900000   \n",
       "1        30.709999            21.331547          18023700      30.010000   \n",
       "2        30.889999            21.456575          12745100      30.090000   \n",
       "3        30.750000            21.359331           6563100      30.340000   \n",
       "4        30.719999            21.338493           6267600      30.290001   \n",
       "\n",
       "   High_Consumer  Low_Consumer  Close_Consumer  Adj Close_Consumer  \\\n",
       "0      30.110001     29.900000       30.000000           25.967613   \n",
       "1      30.139999     29.820000       30.110001           26.062828   \n",
       "2      30.219999     30.020000       30.150000           26.097452   \n",
       "3      30.410000     30.139999       30.400000           26.313848   \n",
       "4      30.410000     30.120001       30.389999           26.305195   \n",
       "\n",
       "   Volume_Consumer  \n",
       "0          5443900  \n",
       "1          6162200  \n",
       "2          4246900  \n",
       "3          5736700  \n",
       "4          6438000  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data\\output.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_Pharm</th>\n",
       "      <th>High_Pharm</th>\n",
       "      <th>Low_Pharm</th>\n",
       "      <th>Close_Pharm</th>\n",
       "      <th>Adj Close_Pharm</th>\n",
       "      <th>Volume_Pharm</th>\n",
       "      <th>Open_Semicon</th>\n",
       "      <th>High_Semicon</th>\n",
       "      <th>Low_Semicon</th>\n",
       "      <th>Close_Semicon</th>\n",
       "      <th>...</th>\n",
       "      <th>Low_Utilities</th>\n",
       "      <th>Close_Utilities</th>\n",
       "      <th>Adj Close_Utilities</th>\n",
       "      <th>Volume_Utilities</th>\n",
       "      <th>Open_Consumer</th>\n",
       "      <th>High_Consumer</th>\n",
       "      <th>Low_Consumer</th>\n",
       "      <th>Close_Consumer</th>\n",
       "      <th>Adj Close_Consumer</th>\n",
       "      <th>Volume_Consumer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-04-01</th>\n",
       "      <td>33.150002</td>\n",
       "      <td>33.544998</td>\n",
       "      <td>33.020000</td>\n",
       "      <td>33.535000</td>\n",
       "      <td>26.125103</td>\n",
       "      <td>1622800</td>\n",
       "      <td>28.350000</td>\n",
       "      <td>28.660000</td>\n",
       "      <td>28.299999</td>\n",
       "      <td>28.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>31.010000</td>\n",
       "      <td>31.080000</td>\n",
       "      <td>21.588554</td>\n",
       "      <td>8217600</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>30.110001</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>25.967613</td>\n",
       "      <td>5443900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-05-01</th>\n",
       "      <td>33.580002</td>\n",
       "      <td>33.580002</td>\n",
       "      <td>33.134998</td>\n",
       "      <td>33.220001</td>\n",
       "      <td>25.879725</td>\n",
       "      <td>1933200</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>28.540001</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>28.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.559999</td>\n",
       "      <td>30.709999</td>\n",
       "      <td>21.331547</td>\n",
       "      <td>18023700</td>\n",
       "      <td>30.010000</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>29.820000</td>\n",
       "      <td>30.110001</td>\n",
       "      <td>26.062828</td>\n",
       "      <td>6162200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-06-01</th>\n",
       "      <td>33.250000</td>\n",
       "      <td>33.384998</td>\n",
       "      <td>33.169998</td>\n",
       "      <td>33.384998</td>\n",
       "      <td>26.008247</td>\n",
       "      <td>1492400</td>\n",
       "      <td>28.209999</td>\n",
       "      <td>28.450001</td>\n",
       "      <td>28.080000</td>\n",
       "      <td>28.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.690001</td>\n",
       "      <td>30.889999</td>\n",
       "      <td>21.456575</td>\n",
       "      <td>12745100</td>\n",
       "      <td>30.090000</td>\n",
       "      <td>30.219999</td>\n",
       "      <td>30.020000</td>\n",
       "      <td>30.150000</td>\n",
       "      <td>26.097452</td>\n",
       "      <td>4246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-07-01</th>\n",
       "      <td>33.285000</td>\n",
       "      <td>33.419998</td>\n",
       "      <td>33.230000</td>\n",
       "      <td>33.330002</td>\n",
       "      <td>25.965412</td>\n",
       "      <td>764600</td>\n",
       "      <td>28.090000</td>\n",
       "      <td>28.160000</td>\n",
       "      <td>27.760000</td>\n",
       "      <td>27.959999</td>\n",
       "      <td>...</td>\n",
       "      <td>30.639999</td>\n",
       "      <td>30.750000</td>\n",
       "      <td>21.359331</td>\n",
       "      <td>6563100</td>\n",
       "      <td>30.340000</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>30.139999</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>26.313848</td>\n",
       "      <td>5736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-01</th>\n",
       "      <td>33.259998</td>\n",
       "      <td>33.369999</td>\n",
       "      <td>33.185001</td>\n",
       "      <td>33.340000</td>\n",
       "      <td>25.973190</td>\n",
       "      <td>1218200</td>\n",
       "      <td>27.940001</td>\n",
       "      <td>28.549999</td>\n",
       "      <td>27.870001</td>\n",
       "      <td>28.520000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.520000</td>\n",
       "      <td>30.719999</td>\n",
       "      <td>21.338493</td>\n",
       "      <td>6267600</td>\n",
       "      <td>30.290001</td>\n",
       "      <td>30.410000</td>\n",
       "      <td>30.120001</td>\n",
       "      <td>30.389999</td>\n",
       "      <td>26.305195</td>\n",
       "      <td>6438000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open_Pharm  High_Pharm  Low_Pharm  Close_Pharm  Adj Close_Pharm  \\\n",
       "Date                                                                          \n",
       "2010-04-01   33.150002   33.544998  33.020000    33.535000        26.125103   \n",
       "2010-05-01   33.580002   33.580002  33.134998    33.220001        25.879725   \n",
       "2010-06-01   33.250000   33.384998  33.169998    33.384998        26.008247   \n",
       "2010-07-01   33.285000   33.419998  33.230000    33.330002        25.965412   \n",
       "2010-08-01   33.259998   33.369999  33.185001    33.340000        25.973190   \n",
       "\n",
       "            Volume_Pharm  Open_Semicon  High_Semicon  Low_Semicon  \\\n",
       "Date                                                                \n",
       "2010-04-01       1622800     28.350000     28.660000    28.299999   \n",
       "2010-05-01       1933200     28.450001     28.540001    28.080000   \n",
       "2010-06-01       1492400     28.209999     28.450001    28.080000   \n",
       "2010-07-01        764600     28.090000     28.160000    27.760000   \n",
       "2010-08-01       1218200     27.940001     28.549999    27.870001   \n",
       "\n",
       "            Close_Semicon  ...  Low_Utilities  Close_Utilities  \\\n",
       "Date                       ...                                   \n",
       "2010-04-01      28.410000  ...      31.010000        31.080000   \n",
       "2010-05-01      28.250000  ...      30.559999        30.709999   \n",
       "2010-06-01      28.180000  ...      30.690001        30.889999   \n",
       "2010-07-01      27.959999  ...      30.639999        30.750000   \n",
       "2010-08-01      28.520000  ...      30.520000        30.719999   \n",
       "\n",
       "            Adj Close_Utilities  Volume_Utilities  Open_Consumer  \\\n",
       "Date                                                               \n",
       "2010-04-01            21.588554           8217600      29.900000   \n",
       "2010-05-01            21.331547          18023700      30.010000   \n",
       "2010-06-01            21.456575          12745100      30.090000   \n",
       "2010-07-01            21.359331           6563100      30.340000   \n",
       "2010-08-01            21.338493           6267600      30.290001   \n",
       "\n",
       "            High_Consumer  Low_Consumer  Close_Consumer  Adj Close_Consumer  \\\n",
       "Date                                                                          \n",
       "2010-04-01      30.110001     29.900000       30.000000           25.967613   \n",
       "2010-05-01      30.139999     29.820000       30.110001           26.062828   \n",
       "2010-06-01      30.219999     30.020000       30.150000           26.097452   \n",
       "2010-07-01      30.410000     30.139999       30.400000           26.313848   \n",
       "2010-08-01      30.410000     30.120001       30.389999           26.305195   \n",
       "\n",
       "            Volume_Consumer  \n",
       "Date                         \n",
       "2010-04-01          5443900  \n",
       "2010-05-01          6162200  \n",
       "2010-06-01          4246900  \n",
       "2010-07-01          5736700  \n",
       "2010-08-01          6438000  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
    "indexeddf = df.set_index(['Date']) # Passed strings into a datetime format using to_datetime (inbuilt function in pandas)\n",
    "from datetime import datetime\n",
    "indexeddf.head(5) # Dates should be bold now and the word \\\"Date\\\" should be of a different row from the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2571, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to pinpoint the variable of interest as well as the shifting rate, which is the amount of days into the future we want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = ['Adj Close_SNP500', 'Close_SNP500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_days = 1\n",
    "shift_steps = 1 * 365 # Number of years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the new dataframe with the time-shifted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = df[targets].shift(-shift_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Ensure that the df has been successfully shifted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close_SNP500</th>\n",
       "      <th>Close_SNP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1132.989990</td>\n",
       "      <td>1132.989990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1136.520020</td>\n",
       "      <td>1136.520020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1137.140015</td>\n",
       "      <td>1137.140015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1141.689941</td>\n",
       "      <td>1141.689941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1144.979980</td>\n",
       "      <td>1144.979980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1265.420044</td>\n",
       "      <td>1265.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1267.640015</td>\n",
       "      <td>1267.640015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>1271.500000</td>\n",
       "      <td>1271.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>1278.359985</td>\n",
       "      <td>1278.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>1295.520020</td>\n",
       "      <td>1295.520020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adj Close_SNP500  Close_SNP500\n",
       "0         1132.989990   1132.989990\n",
       "1         1136.520020   1136.520020\n",
       "2         1137.140015   1137.140015\n",
       "3         1141.689941   1141.689941\n",
       "4         1144.979980   1144.979980\n",
       "..                ...           ...\n",
       "365       1265.420044   1265.420044\n",
       "366       1267.640015   1267.640015\n",
       "367       1271.500000   1271.500000\n",
       "368       1278.359985   1278.359985\n",
       "369       1295.520020   1295.520020\n",
       "\n",
       "[370 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[targets].head(shift_steps + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close_SNP500</th>\n",
       "      <th>Close_SNP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1265.420044</td>\n",
       "      <td>1265.420044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1267.640015</td>\n",
       "      <td>1267.640015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1271.500000</td>\n",
       "      <td>1271.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1278.359985</td>\n",
       "      <td>1278.359985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295.520020</td>\n",
       "      <td>1295.520020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Adj Close_SNP500  Close_SNP500\n",
       "0       1265.420044   1265.420044\n",
       "1       1267.640015   1267.640015\n",
       "2       1271.500000   1271.500000\n",
       "3       1278.359985   1278.359985\n",
       "4       1295.520020   1295.520020"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj Close_SNP500</th>\n",
       "      <th>Close_SNP500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Adj Close_SNP500  Close_SNP500\n",
       "2566               NaN           NaN\n",
       "2567               NaN           NaN\n",
       "2568               NaN           NaN\n",
       "2569               NaN           NaN\n",
       "2570               NaN           NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_targets.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "\n",
    "We now convert the Pandas data-frames to NumPy arrays that can be input to the neural network. We also remove the last part of the numpy arrays, because the target-data has `NaN` for the shifted period, and we only want to have valid data and we need the same array-shapes for the input- and output-data.\n",
    "\n",
    "These are the input-signals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We want to only include data from other industries and NOT SNP500, hence remove them.\n",
    "\n",
    "df = df.drop(['Date'], axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dforiginal = pd.read_csv(\"data\\output.csv\") # Assigning the unedited one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.values[0:-shift_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Shape: (2206, 54)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_data))\n",
    "print(\"Shape:\", x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the output-signals (or target-signals):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = df_targets.values[:-shift_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Shape: (2206, 2)\n"
     ]
    }
   ],
   "source": [
    "print(type(y_data))\n",
    "print(\"Shape:\", y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = len(x_data) # No. of obs\n",
    "train_split = 0.9 # Fraction of data used as training\n",
    "num_train = int(num_data * train_split) # Number of obs used in training set\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test = num_data - num_train # Number of obs used for testing\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of input times: 2206\n"
     ]
    }
   ],
   "source": [
    "x_train = x_data[0:num_train] # Assigning input signals\n",
    "x_test = x_data[num_train:]\n",
    "print('No. of input times: ' + str(len(x_train) + len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of output times: 2206\n"
     ]
    }
   ],
   "source": [
    "y_train = y_data[0:num_train] # Assigning output signals\n",
    "y_test = y_data[num_train:]\n",
    "print('No. of output times: ' + str(len(y_train) + len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of input signals: 54\n"
     ]
    }
   ],
   "source": [
    "num_x_signals = x_data.shape[1]\n",
    "print('No of input signals: ' + str(num_x_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of output signals: 2\n"
     ]
    }
   ],
   "source": [
    "num_y_signals = y_data.shape[1]\n",
    "print('No of output signals: ' + str(num_y_signals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data\n",
    "\n",
    "Look for the range of values in the data-set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 6.054201\n",
      "Max: 10617810000.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(x_train))\n",
    "print(\"Max:\", np.max(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "print(\"Min:\", np.min(x_train_scaled))\n",
    "print(\"Max:\", np.max(x_train_scaled))\n",
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)\n",
    "print(\"Min:\", np.min(y_train_scaled))\n",
    "print(\"Max:\", np.max(y_train_scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Instead of training the Recurrent Neural Network on the complete sequences of almost 300k observations, we will use the following function to create a batch of shorter sub-sequences picked at random from the training-data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        x_shape = (batch_size, sequence_length, num_x_signals)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        y_shape = (batch_size, sequence_length, num_y_signals)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n",
    "            y_batch[i] = y_train_scaled[idx:idx+sequence_length]\n",
    "        \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a large batch-size so as to keep the GPU near 100% work-load. You may have to adjust this number depending on your GPU, its RAM and your choice of `sequence_length` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a sequence length of 365, which corresponds to 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_length = 365\n",
    "sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length) # Creation of batch-generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 365, 54)\n",
      "(144, 365, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27900d79388>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 0   # First sequence in the batch.\n",
    "signal = 0  # First signal from the 20 input-signals.\n",
    "seq = x_batch[batch, :, signal]\n",
    "plt.plot(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x279213cee48>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = y_batch[batch, :, signal]\n",
    "plt.plot(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set\n",
    "\n",
    "The neural network trains quickly so we can easily run many training epochs. But then there is a risk of overfitting the model to the training-set so it does not generalize well to unseen data. We will therefore monitor the model's performance on the test-set after each epoch and only save the model's weights if the performance is improved on the test-set.\n",
    "\n",
    "The batch-generator randomly selects a batch of short sequences from the training-data and uses that during training. But for the validation-data we will instead run through the entire sequence from the test-set and measure the prediction accuracy on that entire sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(x_test_scaled, axis=0),\n",
    "                   np.expand_dims(y_test_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Recurrent Neural Network\n",
    "\n",
    "We are now ready to create the Recurrent Neural Network (RNN). We will use the Keras API for this because of its simplicity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add a Gated Recurrent Unit (GRU) to the network. This will have 512 outputs for each time-step in the sequence.\n",
    "\n",
    "Note that because this is the first layer in the model, Keras needs to know the shape of its input, which is a batch of sequences of arbitrary length (indicated by `None`), where each observation has a number of input-signals (`num_x_signals`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=512,\n",
    "              return_sequences=True,\n",
    "              input_shape=(None, num_x_signals,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GRU outputs a batch of sequences of 512 values. We want to predict 3 output-signals, so we add a fully-connected (or dense) layer which maps 512 values down to only 3 values.\n",
    "\n",
    "The output-signals in the data-set have been limited to be between 0 and 1 using a scaler-object. So we also limit the output of the neural network using the Sigmoid activation function, which squashes the output to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_y_signals, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "We will use Mean Squared Error (MSE) as the loss-function that will be minimized. This measures how closely the model's output matches the true output signals.\n",
    "\n",
    "However, at the beginning of a sequence, the model has only seen input-signals for a few time-steps, so its generated output may be very inaccurate. Using the loss-value for the early time-steps may cause the model to distort its later output. We therefore give the model a \"warmup-period\" of 50 time-steps where we don't use its accuracy in the loss-function, in hope of improving the accuracy for later time-steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse_warmup(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error between y_true and y_pred,\n",
    "    but ignore the beginning \"warmup\" part of the sequences.\n",
    "    \n",
    "    y_true is the desired output.\n",
    "    y_pred is the model's output.\n",
    "    \"\"\"\n",
    "\n",
    "    # The shape of both input tensors are:\n",
    "    # [batch_size, sequence_length, num_y_signals].\n",
    "\n",
    "    # Ignore the \"warmup\" parts of the sequences\n",
    "    # by taking slices of the tensors.\n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "\n",
    "    # These sliced tensors both have this shape:\n",
    "    # [batch_size, sequence_length - warmup_steps, num_y_signals]\n",
    "\n",
    "    # Calculat the Mean Squared Error and use it as loss.\n",
    "    mse = mean(square(y_true_slice - y_pred_slice))\n",
    "    \n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile Model\n",
    "\n",
    "This is the optimizer and the beginning learning-rate that we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 512)         872448    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 2)           1026      \n",
      "=================================================================\n",
      "Total params: 873,474\n",
      "Trainable params: 873,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=1e-3)\n",
    "model.compile(loss=loss_mse_warmup, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Functions\n",
    "\n",
    "During training we want to save checkpoints and log the progress to TensorBoard so we create the appropriate callbacks for Keras.\n",
    "\n",
    "This is the callback for writing checkpoints during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = '23_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5, verbose=1)\n",
    "callback_tensorboard = TensorBoard(log_dir='./23_logs/',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False,\n",
    "                                  profile_batch = 100000000)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard,\n",
    "             callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Recurrent Neural Network\n",
    "\n",
    "We can now train the neural network.\n",
    "\n",
    "Note that a single \"epoch\" does not correspond to a single processing of the training-set, because of how the batch-generator randomly selects sub-sequences from the training-set. Instead we have selected `steps_per_epoch` so that one \"epoch\" is processed in a few minutes.\n",
    "\n",
    "With these settings, each \"epoch\" took about 2.5 minutes to process on a GTX 1070. After 14 \"epochs\" the optimization was stopped because the validation-loss had not decreased for 5 \"epochs\". This optimization took about 35 minutes to finish.\n",
    "\n",
    "Also note that the loss sometimes becomes `NaN` (not-a-number). This is often resolved by restarting and running the Notebook again. But it may also be caused by your neural network architecture, learning-rate, batch-size, sequence-length, etc. in which case you may have to modify those settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 100 steps, validate on 1 samples\n",
      "Epoch 1/20\n",
      " 99/100 [============================>.] - ETA: 4s - loss: 0.0085\n",
      "Epoch 00001: val_loss improved from inf to 0.01693, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 441s 4s/step - loss: 0.0085 - val_loss: 0.0169\n",
      "Epoch 2/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 0.0035 \n",
      "Epoch 00002: val_loss did not improve from 0.01693\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "100/100 [==============================] - 500s 5s/step - loss: 0.0035 - val_loss: 0.0237\n",
      "Epoch 3/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 0.0011 \n",
      "Epoch 00003: val_loss did not improve from 0.01693\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "100/100 [==============================] - 518s 5s/step - loss: 0.0011 - val_loss: 0.0198\n",
      "Epoch 4/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 8.0979e-04 \n",
      "Epoch 00004: val_loss did not improve from 0.01693\n",
      "100/100 [==============================] - 520s 5s/step - loss: 8.0860e-04 - val_loss: 0.0170\n",
      "Epoch 5/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 7.0880e-04 \n",
      "Epoch 00005: val_loss improved from 0.01693 to 0.01645, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 533s 5s/step - loss: 7.0785e-04 - val_loss: 0.0165\n",
      "Epoch 6/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 6.3298e-04 \n",
      "Epoch 00006: val_loss improved from 0.01645 to 0.01580, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 519s 5s/step - loss: 6.3284e-04 - val_loss: 0.0158\n",
      "Epoch 7/20\n",
      " 99/100 [============================>.] - ETA: 5s - loss: 5.8914e-04 \n",
      "Epoch 00007: val_loss improved from 0.01580 to 0.01555, saving model to 23_checkpoint.keras\n",
      "100/100 [==============================] - 522s 5s/step - loss: 5.8907e-04 - val_loss: 0.0156\n",
      "Epoch 8/20\n",
      " 13/100 [==>...........................] - ETA: 7:40 - loss: 5.7136e-04WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x=generator,\n",
    "          epochs=20,\n",
    "          steps_per_epoch=100,\n",
    "          validation_data=validation_data,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
